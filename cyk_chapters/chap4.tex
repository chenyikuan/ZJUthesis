\chapter{级联随机蕨回归框架下的物体六维位姿估计}

\section{概述}

在工业装配现场，为了实现生产过程的高效自动化，很多场合需要对工业零件或是一般物体进行自动化抓取或者放置。目前大多数场合下实现物体的自动化抓取以及放置采取的措施都是通过将被抓去或者放置的物体固定在一些具有非常高精度的位置上，并事先调试好硬代码来控制机械臂等执行机械进行操作。但这个方法需要大量的人力资源对工业现场进行部署，同时物体的位姿估计算法也须要针对每一个零件进行特殊的设计，大大降低了工业生产效率。因此下文将通过讨论一个新颖的物体位姿估计算法，来克服上述几个工业现场存在的问题。

本章的主旨是借鉴人脸特征点定位这个研究领域取得的杰出成果，提出一个更加通用高效的物体六维位姿估计算法框架。通过重新设计全新特征描述，使算法在深度图像上具有较高的信噪比，同时具备一定的尺度不变性。在第二章中已经给出了随机蕨算法的核心功能，本文将借助随机蕨回归算法，将其用于物体的六维位姿估计。其中，提出的新物体位姿估计算法框架需要大量的标记数据进行回归模型的训练，而第三章内容通过仿真深度相机可以在短时间内提供大量的此类数据，为该算法的研究提供了重要支撑。最后本文将进一步探讨遮挡情况下，利用大噪声干扰下的随机蕨回归算法进行异步位姿回归，从而克服遮挡情况对物体位姿回归的影响。

本章结构安排如下：4.2节内容主要讨论深度图像上的新特征设计，以及新特征的哈希处理。4.3节给出了物体位姿估计的主要流程框架以及框架中一些重要的实现细节。4.4节则进一步给出了如何将随机蕨算法改造后应用于遮挡情况下的物体位姿估计。最后通过实验逐一验证上述算法的可行性以及高效性。

\section{深度图像上的特征设计}

类似于SIFT、SURF、FAST等经典的特征描述一般都是针对RGB图像或者灰度图像进行设计的，这些特征描述能够反映出图像特征点周围的色彩或者纹理信息。这些特征点描述一般而言具有相对较高的计算复杂度，从而能够携带非常丰富的信息，因此具有非常好的稳定性。但在物体的位姿估计应用中这些特征描述就相对显得比较乏力，首先这些特征描述无法携带物体的深度信息，在描述深度图像中的特征点的时候不能够具有尺度不变性。也就是说对于物体的同一个特征点，不同的距离下，这些特征描述方法得到的结果都是不一样的。而我们通常希望在描述一个物体的同一个特征点的时候，不管该特征点距离深度相机的远近，都应该具有相同的特征描述。本文将主要针对这个问题介绍一种具有尺度不变性的全新特征描述。

\subsection{深度图像块的特征描述} % 

深度图像和传统RGB图像最本质的区别在于深度图像中每一个像素值反应的是这个位置的物体距离深度相机的距离，而不是这个物体的纹理信息。因此在对深度图像中的某一个位置进行特征描述的时候，应该充分考虑到这个位置本身的深度值，或者说在该处进行特征描述的过程应该是和该位置的深度值成一定函数关系的，如下式所示：
\begin{equation}
	F=D(I(x,y))
\end{equation}
其中$F$表示特征描述，$I$表示深度图像，$I(x,y)$表示在深度图像坐标$(x,y)$处对应点的深度值，$D(\cdot)$特征描述的具体表达形式。

另一方面，考虑到在物体位姿估计过程中，特别是针对工业现场下的物体位姿估计，物体都是具有相对稳定的结构，因此在进行一个物体的位姿描述的时候，不应该只局限于描述物体上某一个点周围的纹理信息，而应该考虑到将整个物体的概况整体描述进特征里。也就是说，在深度图像上进行特征描述的过程，应该是针对一个局部深度图像块的，这个深度图像块的大小根据透视变换的几何性质应该正比于该位置的深度值平方：
\begin{equation}
\begin{aligned}
	& D(I(x,y))\equiv{D_\Delta}(I(x,y)) \\
	& \Delta\propto{I^2(x,y)}
\end{aligned}
\end{equation}

这一点应该类似于目前较为成熟的人脸特征点定位中的特征描述。在对人脸特征点进行定位过程中，由于人脸具有非常强的对称性，脸部很多地方存在局部相似，如果不考虑整个人脸的整体信息进行直接定位回归的话会导致算法极易陷入局部极小值而失败。目前人脸特征点定位领域中表现最好的算法采用的特征描述称为差值形状索引特征（Interpolated shape-indexed features）\cite{burgos2013robust}。如下图所示：
\begin{figure}[htb]
	\centering 
	% \includegraphics[width=\textwidth]{./Pictures/test.jpg} 
	\includegraphics[width=0.8\textwidth]{./mypic/人脸特征描述方法.jpg} 
	\caption{人脸特征描述方法中的差值形状索引特征} 
\end{figure}
图中人脸形状由人脸特征点列构成（图中十字点，为了方便阐述仅画出两个），任意取特征点列中的两个点作为基础点，给一个随机比例差值可以得到一个新的点。所有这些通过差值得到的点像素构成一个集合，两两像素值做差便得到了基础特征描述库。可以看出，在人脸特征点定位中用到的特征描述具有非常简洁的形式：
\begin{equation}
	f_{p_1,p_2}(I)=I(p_1)-I(p_2)
\end{equation}
但事实证明，这样简洁的特征描述确实能够很好地表达出人脸面部特征，并能以此回归出非常精准的特征点定位结果。本文认为这样的特征描述之所以能有非常好的表达能力，关键在于基础特征库的生成是通过整体特征点差值得到的。这一步骤不仅仅能将人脸整体的概况信息包含进去，同时也能够通过差值的方式反映出人脸局部的一些结构信息，实现了从概况到细节的所有信息的融合。因此，本文受该特征描述的启发，结合深度图像本身的特点提出一种全新的特征描述方式。
\begin{figure}[htb]
	\centering 
	% \includegraphics[width=\textwidth]{./Pictures/test.jpg} 
	\includegraphics[width=\textwidth]{./mypic/物体位姿估计特征描述方法.jpg} 
	\caption{物体位姿估计特征描述方法} 
\end{figure}

在给定物体的大致位置后（深度图像中该物体的中心点像素坐标），首先由公式(4-2)给出的关系确定特征描述块的大小，使得特征描述框能够覆盖整个物体。实际算法部署过程中，会事先人为标注一个标准距离$d_0$下特征描述框的大小$S_0$，当遇到新场景下实际物体距离为$d'$时，可以直接计算出新的特征描述框大小：
\begin{equation}
	S'=\left(\frac{d'}{d_0}\right)^2\cdot S_0
\end{equation}

下一步须要将得到的特征描述框进行划分。首先将其均分成5*5个子方块，每个子方块相互紧挨覆盖整个特征描述框，如图4-2中间黑线划分方式。然后再在原始特征描述框的中部取4*4个子方块，每个子方块的大小与先前黑线划分得到的子方块大小相同，并且这16个子方块中的每一个方块都位于黑线划分得到的其中4个方块的交界处。这样总共可以得到41个特征描述框子区域。

得到上述这41个子区域之后，将这41个子区域进行平均采样25个像素点(如图4-2最右侧所示)，第$A_k$个子区域上的点记为$\{d_{k_1},d_{k_2},...,d_{k_n}\}$，总共可以得到1025个特征样本点。但这些像素点的深度值信息过于简单，不能直作为特征，需要进一步处理。对于每一个子区域上的25个像素点，我们计算其深度均值$\bar{d}_k$，并将这25个像素点的深度值减去$\bar{d}_k$。这样在每一个子区域中，串联所有的深度值之差以及该深度均值可以得到一个26纬度的子特征，总共可以得到1066维度的特征。然后继续计算上述所有子区域中采样得到的深度均值的均值：
\begin{equation}
	\bar{d}_{all}=\frac{1}{41}\sum_{k=1}^{41} \bar{d}_k
\end{equation}
再将这41个子区域的均值减去$\bar{d}_{all}$得到另外25维度特征，最后加上$\bar{d}_{all}$本身，一共可以得到1092维度的特征描述。

通过这样将整个特征描述区域进行拆分采样，最后通过相互取均值做差的方式进行特征整合描述，可以充分描述出整个区域上的深度分布情况，同时也将局部特征信息包含进特征描述中形成一个具有非常完备的特征描述形式。并且由于特征描述区域大小是通过实际的深度值计算得到的，因此这种特征描述方式具有很好的尺度不变特性。

\subsection{特征哈希处理} % 

为了使特征描述有更高的信噪比，需要对特征进行降维或者哈希化处理。本文借鉴了F. Shen等人在2015年CVPR中提出的监督学习下的哈希算法\cite{shen2015supervised}，通过适当简化其算法过程，提高其算法效率的同时保持其哈希处理的高信噪比优势。

假设存在$n$个特征样本$X=\{x_i\}^{n}_{i=1}$，并且期望将其在监督学习下降维得到长度为$L$的二进制编码$B=\{b_i\}^{n}_{i=1}\in\{-1,1\}^{L\times n}$来代替它，其中$b_i$表示$x_i$的第$i$列二进制码。同时假设在线性分类情况下，有如下式所示的多分类问题：
\begin{equation}
	y=G(b)=W^{\top}b=\left[w_1^\top,...,w_c^\top\right]^\top
\end{equation}

其中$w_k\in \Re^{L\times 1},k=1,...,C$为第$k$类分类向量，$y\in \Re^{C\times 1}$为类别标签向量。显然，上述问题可以等价于求解下式所示的优化问题：
\begin{equation}
\begin{aligned}
	& \min_{B,W,F} \sum_{i=1}^n L\left(y_i,W^\top b_i\right)+\lambda \|W\|^2 \\
	& \ s.t. \  b_i=sgn\left(F(x_i)\right),i=1,...,n.
\end{aligned}
\end{equation}

这里$L(\cdot)$为损失函数，$\lambda$为正则参数，$Y=\{y_i\}_{i=1}^n\in\Re ^{C\times n}$为真值矩阵。这里将二进制限制放宽为连续函数$F(x)$，同时引入二进制损失项可以得到最后的优化问题如下：
\begin{equation}
\begin{aligned}
	& \min_{B,W,F} \sum_{i=1}^n L\left(y_i,W^\top b_i\right)+\lambda \|W\|^2 + \nu\sum_{i=1}^n \|b_i-F(x_i)\|^2     \\
	& \quad\quad\quad\quad\quad\quad\quad s.t. \  b_i\in\{-1,1\}^L.
\end{aligned}
\end{equation}

此处本文考虑到计算效率，采用线性学习算法来直接构建$F(x)$：
\begin{equation}
\begin{aligned}
	& \quad\quad\quad\quad\quad\quad F(x)=P^\top\phi(x) \\
	& \phi(x)=\left[\exp(\frac{\|x-a_1\|^2}{\sigma}),...,\exp(\frac{\|x-a_m\|^2}{\sigma})\right]
\end{aligned}
\end{equation}
这里$\{a_j\}_{j=1}^m$是从训练样本里随机选择的$m$个锚点。接下来将取$L_2$作为损失函数，分为3步对该问题进行求解：G-Step，F-Step，B-Step：
\begin{itemize}
\item G-Step: 固定$B$，可以以最小二乘形式得到$W$：
\begin{equation}
	W=(BB^\top+\lambda I)^{-1}BY^\top
\end{equation}
\item F-Step: 固定$B$，可以得到$P$：
\begin{equation}
	P=\left(\phi(X)\phi^\top(X)\right)^{-1}\phi(X)B^\top
\end{equation}
\item B-Step: 固定除$B$之外的所有变量，采用DCC算法（discrete cyclic coordinate descent method），可以对$B$进行逐位求解：
\begin{equation}
	B: z=sgn(q-B'^\top W'\nu)
\end{equation}
\end{itemize}
其中$z^\top$表示$B$的第$l$行，$B'$表示矩阵$B$除开$z$后的子矩阵，$q^\top$表示$Q=WY+\nu F(X)$的第$l$行，$Q'$表示矩阵除开$q$后的子矩阵，$\nu^\top$表示$W$矩阵的第$l$行，$W'$表示$W$矩阵除开$\nu$后的子矩阵。

在实际应用过程中，通过不断迭代循环上述三个步骤，代入计算$W$，$P$以及$z$，便可逐步收敛，得到最后的哈希码$B$。

但由于在这个算法中锚点的计算会消耗大量的计算资源，为了提高回归算法的效率，本文舍弃锚点的选取，直接采用原始特征信息作为训练的数据，并同时采用回归目标值作为学习目标直接带入算法，不再将回归目标值映射到分类问题上进行处理。通过上述步骤就可以得到下文所需要用到的用于位姿回归拟合的最终哈希特征。

\section{针对位姿估计的级联回归框架设计}

在传统级联回归框架中，所有级联层之间的功能都是一样的，包括具有完全相同的回归拟合器，也包括完全相同的回归目标。例如，在目前表现最优秀的人脸特征点定位算法中\cite{chen2014joint}，采用改进的随机森林作为回归器，回归目标为每一级回归器当前的特征点坐标与真值之间的偏差。并且，在训练每一级回归器的时候用到的回归器训练参数也都是完全一致的。这样的级联回归框架有如下图所示的大致结构：

图图图图图图
\begin{figure}[htb]
	\centering 
	% \includegraphics[width=\textwidth]{./Pictures/test.jpg} 
	\includegraphics[scale=1.0]{./Pictures/test.jpg} 
	\caption{ljzst} 
\end{figure}

但是在物体的位姿估计问题下，需要回归的目标并不是单纯的某些像素值在图像上的坐标，而是比较抽象的物体的六维空间朝向以及空间坐标。这些抽象的回归目标不能在图像上得到直接的反馈，这就会导致下面这样一个问题：
\begin{itemize}
\item 如果采用各级回归模型都完全一致的级联回归框架，并且每一级的回归器训练目标都直接为物体的当前六维位姿。那么将有如下回归优化目标：
\begin{equation}
\begin{aligned}
	& R^t=\arg \min_R \sum_i \|\hat{S}_i-(S_i^{t-1}+R(x_i,S_i^{t-1}))\|^2. \\
	& S:\{dx,dy,dz,d\theta_x,d\theta_y,d\theta_z\}
\end{aligned}
\end{equation}
其中$R$表示各级的回归拟合器，$S_i$表示当前第$i$级物体的六维位姿，$\hat{S}_i$表示位姿的真值，$x_i$表示当前特征描述框。

结合上一节所述，可以很明显看出，在每一级的位姿估计结果$S_i$更新迭代过程中，至少有这三个维度的更新迭代是没有意义的：$\{d\theta_x,d\theta_y,d\theta_z\}$。也就是说，每当一级回归器得到了回归结果之后，虽然可以更新目标物体的当前位姿，但是目标物体当前的位姿对下一级的回归所需要的特征描述所需要的前提是过饱和的。因为按照上节所述的特征描述方法，仅仅需要得知当前物体在深度图像中的质心像素位置即可，也就是仅仅需要$S$中的前三个空间坐标$\{dx,dy,dz\}$。这样一来，如果级联回归框架中每一级都采用完全相同的回归目标的话，就会产生极大的计算资源浪费，大大降低算法的效率，同时回归目标维度的增加也会大大提高回归器训练所需要的时间，甚至可能导致回归器无法得到可靠的回归结果。
\end{itemize}

为了解决上述问题，本文考虑将原始的级联回归框架拆分成两部分，第一部分用于回归物体的质心空间坐标，第二部分用于回归物体的欧拉角位姿。其中第一部分中，由于物体质心空间坐标可以由第三章中的投影关系给出其与深度图像中像素位置的对应关系，这一部分的回归问题可以转化为标准级联回归问题。而第二部分的回归问题较为复杂，是无法转化为级联回归问题的。但得益于第一部分与第二部分的耦合，如果在第一部分问题得到较好的解决情况下，也就是一旦物体的质心空间位置已经得到了较好的估计，在此基础上再进行物体的空间姿态估计将变为地较为容易，回归目标的复杂度也大大降低。因此，可以考虑使用一个相比质心空间坐标回归器稍微强一点的回归拟合器对物体的欧拉角位姿进行直接拟合。

最后将第一部分的基础级联回归器与第二部分的强回归拟合器按先后顺序再次级联，便可以得到物体位姿估计问题下的最终级联回归算法框架。下图为该复合式级联回归框架的流程图：

图图图图图图
\begin{figure}[htb]
	\centering 
	% \includegraphics[width=\textwidth]{./Pictures/test.jpg} 
	\includegraphics[scale=1.0]{./Pictures/test.jpg} 
	\caption{ljzst} 
\end{figure}


\section{遮挡情况下的物体位姿估计} % 如何估计物体的被遮挡情况

当物体存在遮挡时


\section{实验结果与分析} % 物体检测放在这里讲


测试三种特征描述方式：中心辐射式，不存在中央16式
















